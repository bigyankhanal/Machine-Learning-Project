<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=Generator content="Microsoft Word 15 (filtered)">
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:"Lucida Console";
	panose-1:2 11 6 9 4 5 4 2 2 4;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:0in;
	line-height:107%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
a:link, span.MsoHyperlink
	{color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{color:#954F72;
	text-decoration:underline;}
p
	{margin-right:0in;
	margin-left:0in;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;}
pre
	{mso-style-link:"HTML Preformatted Char";
	margin:0in;
	margin-bottom:.0001pt;
	font-size:10.0pt;
	font-family:"Courier New";}
span.apple-converted-space
	{mso-style-name:apple-converted-space;}
span.HTMLPreformattedChar
	{mso-style-name:"HTML Preformatted Char";
	mso-style-link:"HTML Preformatted";
	font-family:"Courier New";}
.MsoChpDefault
	{font-family:"Calibri",sans-serif;}
.MsoPapDefault
	{margin-bottom:8.0pt;
	line-height:107%;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
-->
</style>

</head>

<body lang=EN-US link=blue vlink="#954F72">

<div class=WordSection1>

<p class=MsoNormal><b><span style='font-size:14.0pt;line-height:107%'>Machine
Learning Project from Coursera</span></b></p>

<p class=MsoNormal><i>Bigyan Khanal </i></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><b><span style='font-size:12.0pt;line-height:107%'>Introduction
to the project</span></b></p>

<p style='margin:0in;margin-bottom:.0001pt;text-align:justify;line-height:18.0pt;
background:white'><span style='font-size:11.0pt;font-family:"Calibri",sans-serif'>This
project is about the predicting the manner in which they did the exercise based
on the historical data obtained from the different accelerometers. </span></p>

<p style='margin:0in;margin-bottom:.0001pt;text-align:justify;line-height:18.0pt;
background:white'><span style='font-size:11.0pt;font-family:"Calibri",sans-serif'>The
human activity recognition research is focused on identifying different
activities, i.e. to predict &quot;which&quot; activity was performed at a
specific point in time. The approach is done in order to identify how well a
Weight Lifting Exercises is performed by the wearer based on the data collected
[1]. </span></p>

<p style='margin:0in;margin-bottom:.0001pt;text-align:justify;line-height:18.0pt;
background:white'><span style='font-size:11.0pt;font-family:"Calibri",sans-serif'>In
this work, six young health participants were asked to perform one set of 10
repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions:</span></p>

<p style='margin-top:0in;margin-right:0in;margin-bottom:0in;margin-left:1.0in;
margin-bottom:.0001pt;text-align:justify;line-height:18.0pt;background:white'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>Class A: Exactly
according to the specification</span></p>

<p style='margin-top:0in;margin-right:0in;margin-bottom:0in;margin-left:1.0in;
margin-bottom:.0001pt;text-align:justify;line-height:18.0pt;background:white'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>Class B: Throwing the
elbows to the front </span></p>

<p style='margin-top:0in;margin-right:0in;margin-bottom:0in;margin-left:1.0in;
margin-bottom:.0001pt;text-align:justify;line-height:18.0pt;background:white'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>Class C: Lifting the
dumbbell only halfway </span></p>

<p style='margin-top:0in;margin-right:0in;margin-bottom:0in;margin-left:1.0in;
margin-bottom:.0001pt;text-align:justify;line-height:18.0pt;background:white'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>Class D: Lowering the
dumbbell only halfway</span></p>

<p style='margin-top:0in;margin-right:0in;margin-bottom:0in;margin-left:1.0in;
margin-bottom:.0001pt;text-align:justify;line-height:18.0pt;background:white'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>Class E: Throwing the
hips to the front.</span></p>

<p style='margin:0in;margin-bottom:.0001pt;text-align:justify;line-height:18.0pt;
background:white'><span style='font-size:11.0pt;font-family:"Calibri",sans-serif'>For
the prediction of the test set, we need to import the data, process it, clean
the data, split the data, train the predictor algorithm, validate it and use
the prediction on the testing data. For prediction algorithm, I have followed
the random forest algorithm since it uses the multiple decision trees to get
the decision and are accurate. </span></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><b><span style='font-size:12.0pt;line-height:107%'>Importing
of the data</span></b></p>

<p class=MsoNormal>The training and test data are available at the website as:</p>

<p class=MsoNormal><a
href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv</a> 
<a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv</a>
</p>

<p class=MsoNormal>Some required library R package are loaded:</p>

<p class=MsoNormal style='text-indent:.5in'><span style='color:#A8D08D'>##
Packages required</span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>library (caret)                                                      <span
style='color:#A8D08D'># classification and regression training</span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>library (randomForest)                                  <span
style='color:#A8D08D'> # for use of random forest</span></p>

<p class=MsoNormal style='text-indent:.5in;line-height:normal'>library(AppliedPredictiveModeling)   
<span style='color:#A8D08D'># Functions and Data Sets for 'Applied Predictive
Modeling'</span></p>

<p class=MsoNormal style='text-indent:.5in;line-height:normal'><span
style='color:#A8D08D'>&nbsp;</span></p>

<p class=MsoNormal style='line-height:normal'>After downloading the data in
.csv format they were read to R as training_data and testing_data and given the
required column names and tested for the similarity in column names of this two
data set which was found to be true.</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'><span style='color:#A8D08D'>#Data Import</span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>setwd(&quot;D:/BIGYAN/Coursera/Machine_learning&quot;)</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>training_data&lt;-read.csv(&quot;pml-training.csv&quot;,
na.strings=c(&quot;NA&quot;,&quot;&quot;), header=TRUE)</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>colnames_training &lt;- colnames(training_data)</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>testing_data&lt;-read.csv(&quot;pml-testing.csv&quot;,
na.strings=c(&quot;NA&quot;,&quot;&quot;), header=TRUE)</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>colnames_testing &lt;- colnames(testing_data)</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>all_training_colnames&lt;-colnames_training[1:length(colnames_training)-1]</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>all_testing_colnames&lt;-colnames_testing[1:length(colnames_testing)-1]</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt;line-height:normal'>all.equal(all_training_colnames,
all_testing_colnames)<span style='color:#A8D08D'> </span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt;line-height:normal'>[[TRUE]]<span
style='color:#A8D08D'>              # TRUE indicate the train data and test
data are in same format</span></p>

<p class=MsoNormal><b><span style='font-size:12.0pt;line-height:107%'>&nbsp;</span></b></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt'><b><span
style='font-size:12.0pt;line-height:107%'>Cleaning the data</span></b></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-align:
justify'>The data seems to have too many missing values replaced with NAs from
the above code so, the columns which NAs are removed and the first some
variables are least significant to the prediction of classe so they are
delated. This way data is cleaned from its raw structure. </p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'><span style='color:#A8D08D'># Cleaning the data</span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>training_data &lt;- training_data[,
colSums(is.na(training_data)) == 0]</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>testing_data &lt;- testing_data[,
colSums(is.na(testing_data)) == 0]</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'><span style='color:#A8D08D'># cleaning the data for
those columns which are least significant to the model</span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>Final_train_Data&lt;- training_data[, -c(1:7)]</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>dim(Final_train_Data)</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>Final_test_Data &lt;- testing_data[, -c(1:7)]</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>dim(Final_test_Data)</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>&nbsp;</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'>Finally, the number of columns (i.e. 23) were same in training and test
data.</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'>&nbsp;</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><b><span style='font-size:12.0pt'>Cutting the data</span></b></p>

<p class=MsoNormal style='text-align:justify'>It becomes necessary to cut the
data into two parts one to build the model based on the training set and the
remaining part is used for the validation of the model. For my case, I have
used ¾th of the data for building model and 1/4<sup>th</sup> for the validation
purpose.</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'><span style='color:#A8D08D'>#Splitting the data</span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>set.seed(33433) </p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>inTrain &lt;-
createDataPartition(Final_train_Data$classe, p = 0.75, list = FALSE)</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>Train_data &lt;- Final_train_Data[inTrain, ]</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>Validation_data &lt;- Final_train_Data[-inTrain, ] </p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-indent:
.5in;line-height:normal'>&nbsp;</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><b><span style='font-size:12.0pt'>Model Building</span></b></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'>For model building, the random forest algorithm was chosen. Prior to
applying random forest, we define the fit control as the 5 fold cross
validation.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt;line-height:normal'><span
style='color:#A8D08D'># Model building using Random Forest</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt;line-height:normal'>fitControl &lt;-
trainControl(method=&quot;cv&quot;, number=5, verboseIter=F)</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt;line-height:normal'>model_fit &lt;-
train(classe ~ ., data=Train_data, method=&quot;rf&quot;, trControl=fitControl)</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt;line-height:normal'>print(model_fit)</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt;line-height:normal'>model_fit$finalModel</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt;line-height:normal'>&nbsp;</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'>With these code, the output as the model fit is obtained as:</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
11.25pt;background:white;word-break:break-all'><span style='font-size:10.0pt;
font-family:"Lucida Console";color:black'>&nbsp;</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>Random Forest </span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>14718 samples</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>   52 predictor</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>    5 classes: 'A', 'B', 'C', 'D', 'E' </span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>&nbsp;</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>No pre-processing</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>Resampling: Cross-Validated (5 fold) </span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>Summary of sample sizes: 11773, 11774, 11775, 11775, 11775 </span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>Resampling results across tuning parameters:</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>&nbsp;</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>  mtry  Accuracy   Kappa    </span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>   2    0.9917789  0.9895994</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>  27    0.9921184  0.9900296</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>  52    0.9872261  0.9838403</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>&nbsp;</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>Accuracy was used to select the optimal model using the largest
value.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:45.8pt;margin-bottom:.0001pt;line-height:11.25pt;background:white;
word-break:break-all'><span style='font-size:10.0pt;font-family:"Lucida Console";
color:black'>The final value used for the model was mtry = 27. </span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
11.25pt;background:white;word-break:break-all'><span style='font-size:10.0pt;
font-family:"Lucida Console";color:black'>&nbsp;</span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
11.25pt;background:white;word-break:break-all'>Observing the final model of the
model_fit we get the output as:</p>

<pre style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:
break-all'><span style='font-family:"Lucida Console";color:black'><br>
Call:</span></pre><pre style='margin-left:45.8pt;line-height:11.25pt;
background:white;word-break:break-all'><span style='font-family:"Lucida Console";
color:black'> randomForest(x = x, y = y, mtry = param$mtry) </span></pre><pre
style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>               Type of random forest: classification</span></pre><pre
style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>                     Number of trees: 500</span></pre><pre
style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>No. of variables tried at each split: 27</span></pre><pre
style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>&nbsp;</span></pre><pre
style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>        OOB estimate of  error rate: 0.59%</span></pre><pre
style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Confusion matrix:</span></pre><pre
style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>     A    B    C    D    E  class.error</span></pre><pre
style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>A 4182    2    0    0    1 0.0007168459</span></pre><pre
style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>B   17 2827    4    0    0 0.0073735955</span></pre><pre
style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>C    0   12 2546    9    0 0.0081807557</span></pre><pre
style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>D    0    1   27 2383    1 0.0120232172</span></pre><pre
style='margin-left:45.8pt;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>E    0    2    4    7 2693 0.0048041390</span></pre>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
11.25pt;background:white;word-break:break-all'>&nbsp;</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
11.25pt;background:white;word-break:break-all'><span style='font-size:10.0pt;
font-family:"Lucida Console";color:black'>&nbsp;</span></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><b><span style='font-size:12.0pt'>Model Evaluation:</span></b></p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-align:
justify;line-height:normal'>We then evaluate the model based on the prediction
function from the package and use the fitted model to predict the label
(classe) in Train_data, and show the confusion matrix to compare the
predicted versus the actual labels. The code for the prediction along with the
confusion matrix is shown as:</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-align:justify;line-height:normal'><span
style='color:#A8D08D'>#Model Evaluation</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-align:justify;line-height:normal'>preds
&lt;- predict(model_fit, newdata=Validation_data)</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-align:justify;line-height:normal'>confusionMatrix(Validation_data$classe,
preds)</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;text-align:
justify;line-height:normal'>&nbsp;</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'>And the confusion matrix obtained for the classe of the validation data
is obtained as:</p>

<pre style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:
break-all'><span style='font-family:"Lucida Console";color:black'>Confusion Matrix and Statistics</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>&nbsp;</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>          Reference</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Prediction    A    B    C    D    E</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>         A 1394    1    0    0    0</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>         B    8  941    0    0    0</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>         C    0    9  844    2    0</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>         D    0    0    7  797    0</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>         E    0    3    0    3  895</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>&nbsp;</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Overall Statistics</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>                                          </span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>               Accuracy : 0.9933          </span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>                 95% CI : (0.9906, 0.9954)</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>    No Information Rate : 0.2859          </span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       </span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>                                          </span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>                  Kappa : 0.9915          </span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'> Mcnemar's Test P-Value : NA              </span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>&nbsp;</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Statistics by Class:</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>&nbsp;</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>                     Class: A Class: B Class: C Class: D Class: E</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Sensitivity            0.9943   0.9864   0.9918   0.9938   1.0000</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Specificity            0.9997   0.9980   0.9973   0.9983   0.9985</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Pos Pred Value         0.9993   0.9916   0.9871   0.9913   0.9933</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Neg Pred Value         0.9977   0.9967   0.9983   0.9988   1.0000</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Prevalence             0.2859   0.1945   0.1735   0.1635   0.1825</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Detection Rate         0.2843   0.1919   0.1721   0.1625   0.1825</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Detection Prevalence   0.2845   0.1935   0.1743   0.1639   0.1837</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Balanced Accuracy      0.9970   0.9922   0.9945   0.9960   0.9993</span></pre><pre
style='line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>&nbsp;</span></pre><pre
style='background:white;word-break:break-all'><b><span style='font-size:12.0pt;
font-family:"Calibri",sans-serif'>Accuracy of the Model</span></b></pre><pre
style='text-align:justify;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>The accuracy of the model was tested with the first element of the confusion matrix with the help of following code:</span></pre><pre
style='margin-left:1.0in;text-align:justify;line-height:11.25pt;background:
white;word-break:break-all'><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
color:#A8D08D'>#Accuracy of the model</span></pre><pre style='margin-left:1.0in;
text-align:justify;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>accuracy_rf &lt;- confusion_rf$overall[1]</span></pre><pre
style='margin-left:1.0in;text-align:justify;line-height:11.25pt;background:
white;word-break:break-all'><span style='font-size:11.0pt;font-family:"Calibri",sans-serif'>accuracy_rf</span></pre><pre
style='margin-left:1.0in;text-align:justify;line-height:11.25pt;background:
white;word-break:break-all'><span style='font-size:11.0pt;font-family:"Calibri",sans-serif'>&nbsp;</span></pre><pre
style='text-align:justify;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>And the accuracy result was obtained as 0.9932708. The model was accurate because the random forests chooses a subset of predictors at each split and&nbsp;de-correlate&nbsp;the trees.</span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>Accuracy </span></pre><pre
style='margin-left:1.0in;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-family:"Lucida Console";color:black'>0.9932708 </span></pre><pre
style='text-align:justify;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>&nbsp;</span></pre><pre
style='text-align:justify;background:white;word-break:break-all'><b><span
style='font-size:12.0pt;font-family:"Calibri",sans-serif'>Prediction on the final set</span></b></pre><pre
style='text-align:justify;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>The model developed was tested on the final test data using the following code:</span></pre><pre
style='margin-left:1.0in;text-align:justify;line-height:11.25pt;background:
white;word-break:break-all'><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
color:#A8D08D'>#Prediction on test Set</span></pre><pre style='margin-left:
1.0in;text-align:justify;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>predict(model_fit, Final_test_Data) </span></pre><pre
style='text-align:justify;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>&nbsp;</span></pre><pre
style='text-align:justify;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>And the result was found as :</span></pre><pre
style='line-height:11.25pt;background:white;word-break:break-all'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>                                         </span><span
style='font-family:"Lucida Console";color:black'>[1] B A B A A E D B A A B C B A E E A B B B</span></pre><pre
style='text-align:justify;line-height:11.25pt;background:white;word-break:break-all'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif'>&nbsp;</span></pre>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'>&nbsp;</p>

<p class=MsoNormal style='margin-bottom:0in;margin-bottom:.0001pt;line-height:
normal'><b><span style='font-size:12.0pt'>References</span></b></p>

<p class=MsoNormal>[1] <a
href="http://groupware.les.inf.puc-rio.br/collaborator.jsf?p1=evelloso"><span
style='color:windowtext;text-decoration:none'>Velloso, E.</span></a>; Bulling,
A.; Gellersen, H.;&nbsp;<a
href="http://groupware.les.inf.puc-rio.br/collaborator.jsf?p1=ugulino"><span
style='color:windowtext;text-decoration:none'>Ugulino, W.</span></a>;&nbsp;<a
href="http://groupware.les.inf.puc-rio.br/collaborator.jsf?p1=hugo"><span
style='color:windowtext;text-decoration:none'>Fuks, H.</span></a>&nbsp;<a
href="http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201"
title="Qualitative Activity Recognition of Weight Lifting Exercises"><span
style='color:windowtext;text-decoration:none'>Qualitative Activity Recognition
of Weight Lifting Exercises</span></a>. Proceedings of 4th International
Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart,
Germany: ACM SIGCHI, 2013</p>

<p class=MsoNormal style='text-align:justify'>&nbsp;</p>

</div>

</body>

</html>
